# by default the Dockerfile specifies these versions: 3.5;5.0;6.0;6.1;7.0;7.5;8.0;8.6+PTX
# however for me to work i had to specify the exact version for my card ( 2060 ) it was 7.5
# https://developer.nvidia.com/cuda-gpus you can find the version for your card here
# Or for a programatic approach run `nvidia-smi --query-gpu=name,compute_cap --format=csv`
TORCH_CUDA_ARCH_LIST=7.5
# Huggingface Token - Set your token here if you want to access models in private or access restricted repos
HF_TOKEN=""
# Set cache env
TRANSFORMERS_CACHE=/app/harmony-speech-engine/cache/
HF_HOME=/app/harmony-speech-engine/cache/

# IP to bind the ports on - use 0.0.0.0 for IPv4 and :: for IPv6
BIND_IP=0.0.0.0
# the port the harmony-speech-engine binds to on the host
ENGINE_HOST_PORT=12080
# the port the harmony-speech-engine binds to inside the container
ENGINE_CONTAINER_PORT=12080
# the port the harmony-speech-ui binds to on the host
UI_HOST_PORT=8081
# the port the harmony-speech-ui binds to inside the container
UI_CONTAINER_PORT=80
