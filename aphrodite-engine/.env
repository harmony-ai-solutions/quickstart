# Specifies the CUDA devices visible for the container
# ID 0 usually is the primary GPU; if running multiple GPUs you may want to specify this more precisely
CUDA_VISIBLE_DEVICES=0
# CUDA_VISIBLE_DEVICES=1,2

# NCCL settings for WSL - comment in if running WSL and you're having issues
#NCCL_DEBUG=INFO
#NCCL_P2P_DISABLE=1  # Disable peer-to-peer if causing issues in WSL
#NCCL_SHM_DISABLE=0  # Ensure shared memory is enabled

# the IP to bind the ports on - use 0.0.0.0 for IPv4 and :: for IPv6
BIND_IP=0.0.0.0
# BIND_IP=::
# the port the aphrodite-engine API binds to on the host
HOST_PORT=2242
# the port the aphrodite-engine API binds to inside the container
CONTAINER_PORT=2242

# Huggingface Token - Set your token here if you want to access models in private or access restricted repos
HF_TOKEN=""

# Aphrodite Engine CLI parameters
# Model to serve
APHRODITE_MODEL=NousResearch/Meta-Llama-3.1-8B-Instruct
# Tensor parallelism (number of GPUs to use, from the GPUs specified in CUDA_VISIBLE_DEVICES variable above)
# Must either be 1, or a multiple of 2 => 2,4,8,16
# When running on CPU, this must also be set to 1
APHRODITE_TENSOR_PARALLEL_SIZE=1
# APHRODITE_TENSOR_PARALLEL_SIZE=8
# API key for OpenAI-compatible requests
# APHRODITE_API_KEY=sk-empty
# Extra command line arguments to be appended to the Aphrodite Engine command
# see https://aphrodite.pygmalion.chat/usage/openai/#command-line-arguments-for-the-server for all available commands
# and https://aphrodite.pygmalion.chat/quantization/quantization-methods/ for quantization format options
APHRODITE_EXTRA_ARGS=""
# APHRODITE_EXTRA_ARGS="--max-model-len 4096 -q fp8"
